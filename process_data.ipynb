{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.12.0\n",
        "!pip install tensorflow==2.4.0\n",
        "!pip install datasets\n",
        "!pip install wandb\n",
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "tBptEMBnaRUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_run = False"
      ],
      "metadata": {
        "id": "A8vPYLBo2AD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import glob\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from langdetect import detect\n",
        "import matplotlib.dates as md\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/My Drive/eu_commission'"
      ],
      "outputs": [],
      "metadata": {
        "id": "_A74NXPnaBRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read in the data"
      ],
      "metadata": {
        "id": "illBgu5VaBRo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fs = glob.glob('data/*/*')\n",
        "fields = ['text', 'lang']\n",
        "metrics = [f'{m}_count' \n",
        "           for m in ['like','quote','reply','retweet']]\n",
        "processed_tws = []\n",
        "for f in fs:\n",
        "    tws = json.load(open(f))['data']\n",
        "    for i in range(len(tws)):\n",
        "        item = {k: tws[i][k] for k in fields}\n",
        "        item.update({k: tws[i]['public_metrics'][k] for k in metrics})\n",
        "        item.update({'created_at': tws[i]['created_at'][:10]})\n",
        "        tws[i] = item\n",
        "    processed_tws += tws"
      ],
      "outputs": [],
      "metadata": {
        "id": "n0qvdf5KaBRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df = pd.DataFrame(processed_tws)\n",
        "df['created_at'] = pd.to_datetime(df['created_at'], infer_datetime_format=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SzmXi2guaBRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tweet volume"
      ],
      "metadata": {
        "id": "dIPpS2DJaBRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "freq_dict = {'D': 'day', 'W': 'week', 'M': 'month'}\n",
        "figsizes = {'D': (50,5), 'W': (50,5), 'M': (30, 5)}\n",
        "formats = {'D': '%Y-%m-%d', 'W': '%Y-%m-%d', 'M': '%Y-%m'}\n",
        "top_dict = {}\n",
        "for freq in ['D']:\n",
        "    fig, ax = plt.subplots(figsize=figsizes[freq])\n",
        "    grouped = df.groupby(pd.Grouper(key='created_at', axis=0, freq=freq)).count().reset_index()\n",
        "    top_dict[freq_dict[freq]] = grouped.sort_values(by='text', ascending=False).head(n=5)[['created_at', 'text']].to_records(index=False)\n",
        "    grouped['smoothed'] = grouped['text'].rolling(7).mean()\n",
        "    # Plot \n",
        "    sns.lineplot(data=grouped, x='created_at', y='text', \n",
        "                 alpha=.2, \n",
        "                 label='per day')\n",
        "    sns.lineplot(data=grouped, x='created_at', y='smoothed', \n",
        "                 label='smoothed avg - 7d', \n",
        "                 color=sns.color_palette()[0])\n",
        "    plt.ylabel(f'Tweets per {freq_dict[freq]}')\n",
        "    plt.xlabel('')\n",
        "    plt.title('Tweet volume')\n",
        "    plt.xticks(rotation=60)\n",
        "    # Make year boundaries\n",
        "    for d in grouped.created_at.dt.year.unique()[1:]:\n",
        "        plt.axvline(x=np.datetime64(f'{d}-01-01'), color='darkgrey', linestyle='--')\n",
        "        plt.annotate(s=d, xy=(np.datetime64(f'{d}-06-01'),120), color='black')\n",
        "    ax.xaxis.set_major_locator(md.MonthLocator())\n",
        "    ax.xaxis.set_major_formatter(md.DateFormatter('%b \\'%y'))\n",
        "    plt.xlim(np.datetime64('2010-05-01'),np.datetime64('2022-08-01'))\n",
        "    plt.savefig('figures/tweet_volume.pdf')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "WoKlfObraBRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(df[df.created_at == np.datetime64(top_dict['day'][1][0])].text.tolist())\n",
        "print(top_dict['day'][1][0])"
      ],
      "outputs": [],
      "metadata": {
        "id": "nCePbdX9aBRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the peaks with highest volumes are related to live tweeting of #EUMFF negotiations, automated posting re: to activity on other websites (Storify), and other. \n",
        "Worth keeping in mind that tweet volume can be a major confounder with this data."
      ],
      "metadata": {
        "id": "O1WLDZnhaBRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional preprocessing\n",
        "- flag retweets and tweets starting with mentions;\n",
        "- strip links;\n",
        "- not removing emojis, hashtags and mentions, for now - but could remove depending on which model we end up using."
      ],
      "metadata": {
        "tags": [],
        "id": "4sSgQudoaBRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def language_detection(s):\n",
        "    try:\n",
        "        return detect(s)\n",
        "    except:\n",
        "        return 'unk'"
      ],
      "outputs": [],
      "metadata": {
        "id": "WY9eUSctaBRu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if first_run is True:\n",
        "  df['is_retweet'] = np.where(df['text'].str.startswith('RT'), 1, 0)\n",
        "  df['is_mention'] = np.where(df['text'].str.startswith('@'), 1, 0)\n",
        "  df['text'] = df['text'].str.replace(r'http.*', '', regex=True)\n",
        "  df = df[df['text'].str.len() > 0]\n",
        "  df['lang_detected'] = df['text'].apply(language_detection)\n",
        "  df[df['lang']!=df['lang_detected']]\n",
        "  df.to_csv('processed/all_tweets.csv', sep=',')"
      ],
      "outputs": [],
      "metadata": {
        "id": "kzgReM8GaBRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Breakdown of number of tweets per language"
      ],
      "metadata": {
        "id": "a2baIsKTaBRv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df = pd.read_csv('processed/all_tweets.csv', sep=',', index_col=0)\n",
        "df.groupby('lang')['text'].count().reset_index().sort_values(by='text', ascending=False).rename({'text': 'count'}, axis=1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eztaNiT4aBRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing tweets not in English, it's mostly translations of English tweets. We know that Twitter's automatic language detection is not great, so double-checking with langdetect and only including tweets tagged as English by both the default tagger and langdetect."
      ],
      "metadata": {
        "id": "5tF9IQ64aBRv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df = df[(df['lang']=='en') & (df['lang_detected']=='en')]"
      ],
      "outputs": [],
      "metadata": {
        "id": "ajIoWc7JaBRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test splits\n",
        "Let's leave out a small dataset for pretraining of our language models. We pick a random set of tweets (if that does not show good results, we could consider balanced sampling over time)."
      ],
      "metadata": {
        "id": "I_S78E8BaBRw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "train_size = 3000\n",
        "val_size = 500\n",
        "\n",
        "train_test = ['train'] * train_size + ['val'] * val_size + ['test'] * (df.shape[0] - train_size - val_size)\n",
        "random.shuffle(train_test)\n",
        "df['pretraining_splits'] = train_test"
      ],
      "outputs": [],
      "metadata": {
        "id": "qG6n2CAjaBRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now let's fine tune some language models on these tweets for better performance. "
      ],
      "metadata": {
        "id": "C45SozOeaBRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _save_results(rlist):\n",
        "  fname = 'logs/pretraining/performances.jsonl'\n",
        "  try:\n",
        "    rdf = pd.read_json(fname, \n",
        "                       orient=\"records\",\n",
        "                       lines=True)\n",
        "    rdf = pd.concat([rdf, pd.DataFrame(rlist)])\n",
        "    \n",
        "  except:\n",
        "    rdf = pd.DataFrame(rlist)\n",
        "  rdf.to_json(fname, orient=\"records\", lines=True)"
      ],
      "metadata": {
        "id": "H0geIHq5rjlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "1Q38f3dj6NGC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from pretrain import Pretrainer\n",
        "models = ['distilbert-base-uncased',\n",
        "          'distilbert-base-uncased-finetuned-sst-2-english',\n",
        "          'cardiffnlp/tweet-topic-21-multi']\n",
        "results = []\n",
        "\n",
        "# Run one that was not run before\n",
        "trainer = Pretrainer('cardiffnlp/tweet-topic-21-multi', df, \n",
        "                     batch_size=4, \n",
        "                     lr=2e-6, \n",
        "                     warmup=12)\n",
        "trainer.compile()\n",
        "r = trainer.fit()\n",
        "results.append(r)\n",
        "trainer.save(f'models/pretrained/{trainer.name}')\n",
        "_save_results(results)\n",
        "\n",
        "# Run missing\n",
        "for lr in [2e-5, 2e-2]: # 2e-6 already run\n",
        "  for batch_size in [4]: # 32, 16 consistently lower\n",
        "    for wu_epochs in [3]: # add 1 and try early stopping with 10\n",
        "      for m in models:\n",
        "          trainer = Pretrainer(m, df, \n",
        "                              batch_size=batch_size, \n",
        "                              lr=lr, \n",
        "                              warmup=batch_size*wu_epochs)\n",
        "          trainer.compile()\n",
        "          r = trainer.fit()\n",
        "          results.append(r)\n",
        "          trainer.save(f'models/pretrained/{trainer.name}')\n",
        "          _save_results(results)"
      ],
      "outputs": [],
      "metadata": {
        "id": "B7s9bh4VaBRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topic modeling\n",
        "Let's move on to modeling the topic of the tweets. We'll try to compare different modeling strategies, and both pretrained and fine-tuned models.\n",
        "Then, we'll try to get an idea of what the evolution of topics has been over time. "
      ],
      "metadata": {
        "id": "dMQIuKpwaBRx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from octis.models.CTM import CTM\n",
        "from octis.dataset.dataset import Dataset\n",
        "from octis.optimization.optimizer import Optimizer\n",
        "from skopt.space.space import Real, Categorical, Integer\n",
        "from octis.evaluation_metrics.coherence_metrics import Coherence"
      ],
      "outputs": [],
      "metadata": {
        "id": "6qRrnkIsaBRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's compare this approach with a simpler topic modeling approach."
      ],
      "metadata": {
        "id": "zu1IFrysaBRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next steps\n",
        "- Try more warmup\n",
        "- Topic modeling\n",
        "  - Compare different approaches, with respect to sanity and fit\n",
        "- Engagement as a function of topic\n",
        "- Collect comments, annotate emotions in comments, plot emotion of reactions as a function of topics\n",
        "    - Also polarization?\n",
        "- Topics & engagement as a function of emotions of EU Commission tweet\n",
        "\n",
        "Other:\n",
        "- Streamline preprocessing"
      ],
      "metadata": {
        "id": "f2g9zpQGaBRy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "akSHRjafaBRy"
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ba954e04f94d5e4970321c570fb05eff7c202d9f1ab5b8ba406812668fc94516"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.4 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}